{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compare PAC of two experimental conditions with cluster-based statistics\n\n\nThis example illustrates how to statistically compare the phase-amplitude\ncoupling results coming from two experimental conditions. In particular, the\nscript below a the cluster-based approach to correct for the multiple\ncomparisons.\n\nIn order to work, this script requires MNE-Python package to be installed in\norder to perform the cluster-based correction\n(:func:`mne.stats.permutation_cluster_test`)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom tensorpac import Pac\nfrom tensorpac.signals import pac_signals_wavelet\n\nfrom mne.stats import permutation_cluster_test\n\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulate the data coming from two experimental conditions\n##############################################################################\n Let's start by simulating data coming from two experimental conditions. The\n first dataset is going to simulate a 10hz phase <-> 120hz amplitude\n coupling while the second dataset will not include any coupling (random data)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create the first dataset with a 10hz <-> 100hz coupling\nn_epochs = 30   # number of datasets\nsf = 512.       # sampling frequency\nn_times = 4000  # Number of time points\nx_1, time = pac_signals_wavelet(sf=sf, f_pha=10, f_amp=120, noise=2.,\n                             n_epochs=n_epochs, n_times=n_times)\n# create a second random dataset without any coupling\nx_2 = np.random.rand(n_epochs, n_times)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the single trial PAC on both datasets\n##############################################################################\n once the datasets created, we can now extract the PAC, computed across\n time-points for each trials and across several phase and amplitude\n frequencies\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create the pac object. Use the Gaussian-Copula PAC\np = Pac(idpac=(6, 0, 0), f_pha='hres', f_amp='hres', dcomplex='wavelet')\n# compute pac for both dataset\npac_1 = p.filterfit(sf, x_1, n_jobs=-1)\npac_2 = p.filterfit(sf, x_2, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correct for multiple-comparisons using a cluster-based approach\n##############################################################################\n Then, we perform the cluster-based correction for multiple comparisons\n between the PAC coming from the two conditions. To this end we use the\n Python package MNE-Python and in particular, the function\n :func:`mne.stats.permutation_cluster_test`\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# mne requires that the first is represented by the number of trials (n_epochs)\n# Therefore, we transpose the output PACs of both conditions\npac_r1 = np.transpose(pac_1, (2, 0, 1))\npac_r2 = np.transpose(pac_2, (2, 0, 1))\n\nn_perm = 1000  # number of permutations\ntail = 1       # only inspect the upper tail of the distribution\n# perform the correction\nt_obs, clusters, cluster_p_values, h0 = permutation_cluster_test(\n    [pac_r1, pac_r2], n_permutations=n_perm, tail=tail)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the significant clusters\n##############################################################################\n Finally, we plot the significant clusters. To this end, we used an elegant\n solution proposed by MNE where the non significant part appears using a\n gray scale colormap while significant clusters are going to be color coded.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create new stats image with only significant clusters\nt_obs_plot = np.nan * np.ones_like(t_obs)\nfor c, p_val in zip(clusters, cluster_p_values):\n    if p_val <= 0.001:\n        t_obs_plot[c] = t_obs[c]\n        t_obs[c] = np.nan\n\ntitle = 'Cluster-based corrected differences\\nbetween cond 1 and 2'\np.comodulogram(t_obs, cmap='gray', colorbar=False)\np.comodulogram(t_obs_plot, cmap='viridis', title=title)\nplt.gca().invert_yaxis()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}