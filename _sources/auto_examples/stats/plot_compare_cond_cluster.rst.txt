.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_stats_plot_compare_cond_cluster.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_stats_plot_compare_cond_cluster.py:


========================================================================
Compare PAC of two experimental conditions with cluster-based statistics
========================================================================

This example illustrates how to statistically compare the phase-amplitude
coupling results coming from two experimental conditions. In particular, the
script below a the cluster-based approach to correct for the multiple
comparisons.

In order to work, this script requires MNE-Python package to be installed in
order to perform the cluster-based correction
(:func:`mne.stats.permutation_cluster_test`)


.. code-block:: default

    import numpy as np

    from tensorpac import Pac
    from tensorpac.signals import pac_signals_wavelet

    from mne.stats import permutation_cluster_test

    import matplotlib.pyplot as plt








Simulate the data coming from two experimental conditions
##############################################################################
 Let's start by simulating data coming from two experimental conditions. The
 first dataset is going to simulate a 10hz phase <-> 120hz amplitude
 coupling while the second dataset will not include any coupling (random data)


.. code-block:: default


    # create the first dataset with a 10hz <-> 100hz coupling
    n_epochs = 30   # number of datasets
    sf = 512.       # sampling frequency
    n_times = 4000  # Number of time points
    x_1, time = pac_signals_wavelet(sf=sf, f_pha=10, f_amp=120, noise=2.,
                                 n_epochs=n_epochs, n_times=n_times)
    # create a second random dataset without any coupling
    x_2 = np.random.rand(n_epochs, n_times)







Compute the single trial PAC on both datasets
##############################################################################
 once the datasets created, we can now extract the PAC, computed across
 time-points for each trials and across several phase and amplitude
 frequencies


.. code-block:: default


    # create the pac object. Use the Gaussian-Copula PAC
    p = Pac(idpac=(6, 0, 0), f_pha='hres', f_amp='hres', dcomplex='wavelet')
    # compute pac for both dataset
    pac_1 = p.filterfit(sf, x_1, n_jobs=-1)
    pac_2 = p.filterfit(sf, x_2, n_jobs=-1)







Correct for multiple-comparisons using a cluster-based approach
##############################################################################
 Then, we perform the cluster-based correction for multiple comparisons
 between the PAC coming from the two conditions. To this end we use the
 Python package MNE-Python and in particular, the function
 :func:`mne.stats.permutation_cluster_test`


.. code-block:: default


    # mne requires that the first is represented by the number of trials (n_epochs)
    # Therefore, we transpose the output PACs of both conditions
    pac_r1 = np.transpose(pac_1, (2, 0, 1))
    pac_r2 = np.transpose(pac_2, (2, 0, 1))

    n_perm = 1000  # number of permutations
    tail = 1       # only inspect the upper tail of the distribution
    # perform the correction
    t_obs, clusters, cluster_p_values, h0 = permutation_cluster_test(
        [pac_r1, pac_r2], n_permutations=n_perm, tail=tail)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Using a threshold of 4.006873
    stat_fun(H1): min=0.000000 max=73.689878
    Running initial clustering
    Found 14 clusters
    Permuting 999 times...
      0%|          |  : 0/999 [00:00<?,       ?it/s]      2%|1         |  : 15/999 [00:00<00:02,  438.54it/s]      3%|3         |  : 30/999 [00:00<00:02,  438.60it/s]      5%|4         |  : 46/999 [00:00<00:02,  440.07it/s]      6%|6         |  : 61/999 [00:00<00:02,  440.14it/s]      8%|7         |  : 76/999 [00:00<00:02,  440.23it/s]      9%|9         |  : 93/999 [00:00<00:02,  442.86it/s]     11%|#         |  : 108/999 [00:00<00:02,  442.79it/s]     12%|#2        |  : 123/999 [00:00<00:01,  442.75it/s]     14%|#3        |  : 138/999 [00:00<00:01,  442.66it/s]     15%|#5        |  : 153/999 [00:00<00:01,  442.56it/s]     17%|#7        |  : 171/999 [00:00<00:01,  446.13it/s]     19%|#8        |  : 186/999 [00:00<00:01,  445.85it/s]     20%|##        |  : 202/999 [00:00<00:01,  447.04it/s]     22%|##1       |  : 217/999 [00:00<00:01,  446.67it/s]     23%|##3       |  : 233/999 [00:00<00:01,  447.81it/s]     25%|##4       |  : 249/999 [00:00<00:01,  448.83it/s]     26%|##6       |  : 264/999 [00:00<00:01,  448.33it/s]     28%|##8       |  : 280/999 [00:00<00:01,  449.36it/s]     30%|##9       |  : 297/999 [00:00<00:01,  451.65it/s]     31%|###1      |  : 313/999 [00:00<00:01,  452.59it/s]     33%|###2      |  : 329/999 [00:00<00:01,  453.50it/s]     34%|###4      |  : 344/999 [00:00<00:01,  452.79it/s]     36%|###6      |  : 360/999 [00:00<00:01,  453.51it/s]     38%|###7      |  : 375/999 [00:00<00:01,  452.78it/s]     39%|###9      |  : 391/999 [00:00<00:01,  453.67it/s]     41%|####      |  : 407/999 [00:00<00:01,  454.52it/s]     43%|####2     |  : 426/999 [00:00<00:01,  458.72it/s]     44%|####4     |  : 442/999 [00:00<00:01,  459.11it/s]     46%|####5     |  : 458/999 [00:00<00:01,  459.62it/s]     47%|####7     |  : 473/999 [00:01<00:01,  458.66it/s]     49%|####8     |  : 489/999 [00:01<00:01,  459.24it/s]     50%|#####     |  : 504/999 [00:01<00:01,  458.36it/s]     52%|#####1    |  : 519/999 [00:01<00:01,  457.43it/s]     54%|#####3    |  : 535/999 [00:01<00:01,  458.09it/s]     55%|#####5    |  : 551/999 [00:01<00:00,  458.69it/s]     57%|#####6    |  : 566/999 [00:01<00:00,  457.79it/s]     58%|#####8    |  : 581/999 [00:01<00:00,  456.97it/s]     60%|#####9    |  : 597/999 [00:01<00:00,  457.61it/s]     61%|######1   |  : 613/999 [00:01<00:00,  458.22it/s]     63%|######2   |  : 629/999 [00:01<00:00,  458.86it/s]     64%|######4   |  : 644/999 [00:01<00:00,  457.94it/s]     66%|######6   |  : 661/999 [00:01<00:00,  459.88it/s]     68%|######7   |  : 677/999 [00:01<00:00,  460.40it/s]     69%|######9   |  : 693/999 [00:01<00:00,  460.93it/s]     71%|#######   |  : 709/999 [00:01<00:00,  461.44it/s]     72%|#######2  |  : 724/999 [00:01<00:00,  460.41it/s]     74%|#######4  |  : 740/999 [00:01<00:00,  460.90it/s]     76%|#######5  |  : 755/999 [00:01<00:00,  459.89it/s]     77%|#######7  |  : 771/999 [00:01<00:00,  460.44it/s]     79%|#######8  |  : 786/999 [00:01<00:00,  459.39it/s]     80%|########  |  : 802/999 [00:01<00:00,  459.96it/s]     82%|########1 |  : 817/999 [00:01<00:00,  459.05it/s]     83%|########3 |  : 834/999 [00:01<00:00,  460.94it/s]     85%|########4 |  : 849/999 [00:01<00:00,  459.90it/s]     86%|########6 |  : 864/999 [00:01<00:00,  458.96it/s]     88%|########8 |  : 880/999 [00:01<00:00,  459.57it/s]     90%|########9 |  : 895/999 [00:01<00:00,  458.66it/s]     91%|#########1|  : 911/999 [00:01<00:00,  459.25it/s]     93%|#########2|  : 926/999 [00:02<00:00,  458.36it/s]     95%|#########4|  : 945/999 [00:02<00:00,  462.49it/s]     96%|#########6|  : 960/999 [00:02<00:00,  461.42it/s]     98%|#########7|  : 975/999 [00:02<00:00,  460.35it/s]     99%|#########9|  : 991/999 [00:02<00:00,  460.83it/s]    100%|##########|  : 999/999 [00:02<00:00,  459.08it/s]    100%|##########|  : 999/999 [00:02<00:00,  461.95it/s]
    Computing cluster p-values
    Done.



Plot the significant clusters
##############################################################################
 Finally, we plot the significant clusters. To this end, we used an elegant
 solution proposed by MNE where the non significant part appears using a
 gray scale colormap while significant clusters are going to be color coded.


.. code-block:: default



    # create new stats image with only significant clusters
    t_obs_plot = np.nan * np.ones_like(t_obs)
    for c, p_val in zip(clusters, cluster_p_values):
        if p_val <= 0.001:
            t_obs_plot[c] = t_obs[c]
            t_obs[c] = np.nan

    title = 'Cluster-based corrected differences\nbetween cond 1 and 2'
    p.comodulogram(t_obs, cmap='gray', colorbar=False)
    p.comodulogram(t_obs_plot, cmap='viridis', title=title)
    plt.gca().invert_yaxis()
    plt.show()



.. image:: /auto_examples/stats/images/sphx_glr_plot_compare_cond_cluster_001.png
    :class: sphx-glr-single-img





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  28.379 seconds)


.. _sphx_glr_download_auto_examples_stats_plot_compare_cond_cluster.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_compare_cond_cluster.py <plot_compare_cond_cluster.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_compare_cond_cluster.ipynb <plot_compare_cond_cluster.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
